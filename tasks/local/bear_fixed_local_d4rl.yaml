name: 'training spawner with single fixed hp set'

resources:
  conda_env: 'pytorch'
  wandb_project: 'flareon'
  num_workers: 4
  cluster: 'local'

logging:
  record: false

parameters:
  # Generic
  task: 'train'
  algo: 'bear'
  cuda: false
  num_seeds: 3
  benchmark: 'd4rl'

  # Training
  save_frequency: 1e5
  num_timesteps: 1e6
  training_steps_per_iter: 2
  eval_steps_per_iter: 10
  eval_frequency: 5e3

  # Model
  layer_norm: true

  # Optimization
  actor_lr: 1.0e-3
  critic_lr: 1.0e-3
  with_scheduler: false
  clip_norm: 0.
  wd_scale: 0.

  # Algorithm
  batch_size: 256
  gamma: 0.99
  mem_size: 1e6
  polyak: 0.005
  targ_up_freq: 100
  n_step_returns: false
  lookahead: 10
  ret_norm: false
  popart: false

  # TD3
  clipped_double: true
  targ_actor_smoothing: false
  td3_std: 0.2
  td3_c: 0.5
  actor_update_delay: 1

  # Prioritized replay
  prioritized_replay: false
  alpha: 0.3
  beta: 1.
  ranked: false
  unreal: false

  # Distributional RL
  use_c51: false
  use_qr: false
  c51_num_atoms: 21
  c51_vmin: -10.
  c51_vmax: 10.
  num_tau: 200

  # Offline RL
  offline: true
  use_expert_demos: false
  sub_rate: 20

  # SAC, BCQ, BEAR
  state_dependent_std: false
  vae_lr: 3.0e-4
  use_adaptive_alpha: false
  alpha_lr: 30.
