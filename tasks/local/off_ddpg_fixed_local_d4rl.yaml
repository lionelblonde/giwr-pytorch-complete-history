name: 'training spawner with single fixed hp set'

resources:
  conda_env: 'pytorch'
  wandb_project: 'flareon'
  num_workers: 4
  cluster: 'local'

logging:
  record: false

parameters:
  # Generic
  task: 'train'
  algo: 'ddpg'
  cuda: false
  num_seeds: 3
  benchmark: 'd4rl'

  # Training
  save_frequency: 1e5
  num_steps: 5e5
  training_steps_per_iter: 1
  eval_steps_per_iter: 10
  eval_frequency: 10

  # Model
  perception_stack: '"400 300, 400 300"'
  layer_norm: true

  # Optimization
  actor_lr: 1.0e-4
  critic_lr: 1.0e-3
  lr_schedule: 'linear'
  clip_norm: 0.
  wd_scale: 0.

  # Algorithm
  rollout_len: 2
  batch_size: 64
  gamma: 0.99
  mem_size: 100000
  noise_type: '"adaptive-param_0.2, ou_0.2"'
  pn_adapt_frequency: 50
  polyak: 0.005
  targ_up_freq: 100
  n_step_returns: true
  lookahead: 10
  ret_norm: false
  popart: false

  # TD3
  clipped_double: true
  ensemble_q_lambda: 1.
  targ_actor_smoothing: true
  td3_std: 0.2
  td3_c: 0.5
  actor_update_delay: 2

  # Prioritized replay
  prioritized_replay: false
  alpha: 0.3
  beta: 1.
  ranked: false
  unreal: false

  # Distributional RL
  use_c51: false
  use_qr: false
  c51_num_atoms: 21
  c51_vmin: -10.
  c51_vmax: 10.
  num_tau: 200

  # Offline RL
  offline: true
  use_expert_demos: false
  sub_rate: 20
