logger configured [master]
  directory: /Users/lionelblonde/Code/offline-batch-rl-pytorch/data/logs/tashee_wepee_shahee.gitSHA_5574e21.halfcheetah-expert-v0.bear_1.seed01
  output formats: ['stdout', 'log', 'csv']
experiment configured [1 MPI workers]
device in use: cpu
the dataset contains 999000 transitions
the dataset contains 999 completed trajectories
the dataset contains 999 orphan transitions
the dataset contains 998001 transitions after removing orphans
key(obs0) -> shape((998001, 17))
key(acs) -> shape((998001, 6))
key(rews) -> shape((998001,))
key(dones1) -> shape((998001,))
key(obs1) -> shape((998001, 17))
key(acs1) -> shape((998001, 6))
key(rets) -> shape((998001,))
the dataset went through these size changes: 999000 -> 998001
over-writting memory size: 2000000 -> 998001
RMIN=-3.094374895095825, RMAX=15.742830276489258
>>>> logging env "<TimeLimitNormalized: <OfflineHalfCheetahEnv instance>>" specs
[INFO] shapes: {'ob_shape': (17,), 'ac_shape': (6,)}.
clip_norm=0.0 <= 0, hence disabled.
workers all synced with root
workers all synced with root
>>>> setting up replay buffer
ReplayBuffer(capacity=998001) configured
loaded replay buffer: 998001/998001 (100%)
>>>> logging actr specs
TanhGaussActor(
  (fc_stack): Sequential(
    (fc_block_1): Sequential(
      (fc): Linear(in_features=17, out_features=256, bias=True)
      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
    (fc_block_2): Sequential(
      (fc): Linear(in_features=256, out_features=256, bias=True)
      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
  )
  (head): Linear(in_features=256, out_features=12, bias=True)
)
total trainable params: 74.51 k.
>>>> logging crit specs
Critic(
  (fc_stack): Sequential(
    (fc_block_1): Sequential(
      (fc): Linear(in_features=23, out_features=256, bias=True)
      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
    (fc_block_2): Sequential(
      (fc): Linear(in_features=256, out_features=256, bias=True)
      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
  )
  (head): Linear(in_features=256, out_features=1, bias=True)
)
total trainable params: 73.22 k.
>>>> logging twin specs
Critic(
  (fc_stack): Sequential(
    (fc_block_1): Sequential(
      (fc): Linear(in_features=23, out_features=256, bias=True)
      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
    (fc_block_2): Sequential(
      (fc): Linear(in_features=256, out_features=256, bias=True)
      (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
  )
  (head): Linear(in_features=256, out_features=1, bias=True)
)
total trainable params: 73.22 k.
>>>> logging vae specs
ActorVAE(
  (encoder): Sequential(
    (fc_block_1): Sequential(
      (fc): Linear(in_features=23, out_features=750, bias=True)
      (ln): LayerNorm((750,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
    (fc_block_2): Sequential(
      (fc): Linear(in_features=750, out_features=750, bias=True)
      (ln): LayerNorm((750,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
  )
  (mean_head): Linear(in_features=750, out_features=12, bias=True)
  (log_std_head): Linear(in_features=750, out_features=12, bias=True)
  (decoder): Sequential(
    (fc_block_1): Sequential(
      (fc): Linear(in_features=29, out_features=750, bias=True)
      (ln): LayerNorm((750,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
    (fc_block_2): Sequential(
      (fc): Linear(in_features=750, out_features=750, bias=True)
      (ln): LayerNorm((750,), eps=1e-05, elementwise_affine=True)
      (nl): ReLU()
    )
  )
  (ac_head): Linear(in_features=750, out_features=6, bias=True)
)
total trainable params: 1.2 M.
wandb co established!
[34m>>>>>>>>>>>>>>>>>>> iteration [0/500000] | elapsed time: less than a minute[0m
time to checkpoint. Saving model @: /Users/lionelblonde/Code/offline-batch-rl-pytorch/data/checkpoints/tashee_wepee_shahee.gitSHA_5574e21.halfcheetah-expert-v0.bear_1.seed01
